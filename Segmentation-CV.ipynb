{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRAIrdQ1sDnu"
      },
      "source": [
        "# U-Net Image Segmentation of Hep2 Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILcwq6pLlu10"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipqRyABxiEwp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import backend as K\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4kaTB90lr6x"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI9M6XiLjNDD"
      },
      "outputs": [],
      "source": [
        "def display(display_list):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    title = [\"Input Image\", \"True Mask\", \"Predicted Mask\"]\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]), cmap='gray')\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "def get_image_paths(main_path):\n",
        "    image_paths, mask_paths = [], []\n",
        "    for folder in os.listdir(main_path):\n",
        "        for filename in os.listdir(os.path.join(main_path, folder)):\n",
        "            if filename.endswith('.bmp'):\n",
        "                if 'mask' in filename:\n",
        "                    mask_paths.append(os.path.join(main_path, folder, filename))\n",
        "                else:\n",
        "                    image_paths.append(os.path.join(main_path, folder, filename))\n",
        "    return image_paths, mask_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5S0jpAHjNfq"
      },
      "outputs": [],
      "source": [
        "def resize(image, mask):\n",
        "    image = tf.image.resize(image, (128, 128), method=\"nearest\")\n",
        "    mask = tf.image.resize(mask, (128, 128), method=\"nearest\")\n",
        "    return image, mask\n",
        "\n",
        "def augment(image, mask):\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        mask = tf.image.flip_left_right(mask)\n",
        "    return image, mask\n",
        "\n",
        "def normalize(image, mask):\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    mask = tf.cast(mask, tf.float32)\n",
        "    # mask -= 1\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjBkXl7hjXkL"
      },
      "outputs": [],
      "source": [
        "def load_image_train(image_path, mask_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.io.decode_bmp(image, channels=3)\n",
        "    image = tf.image.rgb_to_grayscale(image)\n",
        "    image = tf.image.convert_image_dtype(image, \"float32\")\n",
        "\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.io.decode_bmp(mask, channels=0)\n",
        "    mask = tf.image.convert_image_dtype(mask, \"float32\")\n",
        "\n",
        "    image, mask = resize(image, mask)\n",
        "    image, mask = augment(image, mask)\n",
        "    image, mask = normalize(image, mask)\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "def load_image_test(image_path, mask_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.io.decode_bmp(image, channels=3)\n",
        "    image = tf.image.rgb_to_grayscale(image)\n",
        "    image = tf.image.convert_image_dtype(image, \"float32\")\n",
        "\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.io.decode_bmp(mask, channels=0)\n",
        "    mask = tf.image.convert_image_dtype(mask, \"float32\")\n",
        "\n",
        "    image, mask = resize(image, mask)\n",
        "    image, mask = normalize(image, mask)\n",
        "\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO4dJ7Ztjb7j"
      },
      "outputs": [],
      "source": [
        "val_samples = 7\n",
        "main_path = 'MIVIA Lab/Main_Dataset/Images'\n",
        "\n",
        "image_paths, mask_paths = get_image_paths(main_path)\n",
        "train_image_paths, train_mask_paths = image_paths[:-val_samples], mask_paths[:-val_samples]\n",
        "test_image_paths, test_mask_paths = image_paths[-val_samples:], mask_paths[-val_samples:]\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, train_mask_paths))\n",
        "train_dataset = train_dataset.map(load_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_image_paths, test_mask_paths))\n",
        "test_dataset = test_dataset.map(load_image_test, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChZJ1ReeldQP"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 4\n",
        "BUFFER_SIZE = 28\n",
        "\n",
        "batches = dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "batches = batches.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "train_batches = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_batches = train_batches.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "validation_batches = test_dataset.take(7).batch(BATCH_SIZE)\n",
        "test_batches = test_dataset.skip(0).take(7).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JErP-h6i37Fc"
      },
      "outputs": [],
      "source": [
        "sample_batch = next(iter(train_batches))\n",
        "random_index = np.random.choice(sample_batch[0].shape[0])\n",
        "sample_image, sample_mask = sample_batch[0][random_index], sample_batch[1][random_index]\n",
        "display([sample_image, sample_mask])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DQLn-oGmAJe"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpRMSHmJl6PF"
      },
      "outputs": [],
      "source": [
        "def double_conv_block(x, n_filters):\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhMNOCm1mDL4"
      },
      "outputs": [],
      "source": [
        "def downsample_block(x, n_filters):\n",
        "   f = double_conv_block(x, n_filters)\n",
        "   p = layers.MaxPool2D(2)(f)\n",
        "   p = layers.Dropout(0.3)(p)\n",
        "   return f, p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxszHh0YmHfX"
      },
      "outputs": [],
      "source": [
        "def upsample_block(x, conv_features, n_filters):\n",
        "   x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
        "   x = layers.concatenate([x, conv_features])\n",
        "   x = layers.Dropout(0.3)(x)\n",
        "   x = double_conv_block(x, n_filters)\n",
        "   return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chp3ImjhmM2g"
      },
      "source": [
        "## U-Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slJ2eFEAmNrt"
      },
      "outputs": [],
      "source": [
        "def build_unet_model():\n",
        "    inputs = layers.Input(shape=(128,128,3))\n",
        "    f1, p1 = downsample_block(inputs, 64)\n",
        "    f2, p2 = downsample_block(p1, 128)\n",
        "    f3, p3 = downsample_block(p2, 256)\n",
        "    f4, p4 = downsample_block(p3, 512)\n",
        "    bottleneck = double_conv_block(p4, 1024)\n",
        "    u6 = upsample_block(bottleneck, f4, 512)\n",
        "    u7 = upsample_block(u6, f3, 256)\n",
        "    u8 = upsample_block(u7, f2, 128)\n",
        "    u9 = upsample_block(u8, f1, 64)\n",
        "    outputs = layers.Conv2D(1, 1, padding=\"same\", activation = \"sigmoid\")(u9)\n",
        "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
        "    return unet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4o8E0rCGmZH2"
      },
      "outputs": [],
      "source": [
        "unet_model = build_unet_model()\n",
        "unet_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0Go2M8Sm2Al"
      },
      "source": [
        "## Compile and Train U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upJsADvdEpET"
      },
      "outputs": [],
      "source": [
        "def f1_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "def dice_loss(targets, inputs, smooth=1e-6):\n",
        "    inputs = K.flatten(inputs)\n",
        "    targets = K.flatten(targets)\n",
        "    intersection = K.sum(inputs * targets)\n",
        "    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
        "    return 1 - dice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYoh9iN4m2xu"
      },
      "outputs": [],
      "source": [
        "unet_model.compile(optimizer=tf.keras.optimizers.SGD(),\n",
        "                  loss=dice_loss,\n",
        "                  metrics=['accuracy',\n",
        "                           tf.keras.metrics.Precision(name='precision'),\n",
        "                           tf.keras.metrics.Recall(name='recall'),\n",
        "                           tf.keras.metrics.BinaryIoU(name='iou'),\n",
        "                           f1_score])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83gFxpe6m7zn"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 10\n",
        "\n",
        "TRAIN_LENGTH = len(train_dataset)\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
        "\n",
        "VAL_SUBSPLITS = 1\n",
        "TEST_LENTH = len(test_dataset)\n",
        "VALIDATION_STEPS = TEST_LENTH // BATCH_SIZE // VAL_SUBSPLITS\n",
        "\n",
        "model_history = unet_model.fit(train_batches,\n",
        "                              epochs=NUM_EPOCHS,\n",
        "                              steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                              validation_steps=VALIDATION_STEPS,\n",
        "                              validation_data=validation_batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzQxIudtnE_d"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58umsIrb102F"
      },
      "outputs": [],
      "source": [
        "def display_learning_curves(history):\n",
        "    loss = history.history[\"loss\"]\n",
        "    val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "    iou=history.history['iou']\n",
        "    val_iou=history.history['iou']\n",
        "\n",
        "    acc = history.history[\"accuracy\"]\n",
        "    val_acc = history.history[\"val_accuracy\"]\n",
        "\n",
        "    precision=history.history[\"precision\"]\n",
        "    val_precision=history.history[\"val_precision\"]\n",
        "\n",
        "    recall=history.history[\"recall\"]\n",
        "    val_recall=history.history[\"val_recall\"]\n",
        "\n",
        "    f1 = history.history[\"f1_score\"]\n",
        "    val_f1 = history.history[\"val_f1_score\"]\n",
        "\n",
        "    epochs_range = range(NUM_EPOCHS)\n",
        "\n",
        "    fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "    plt.subplot(3,2,1)\n",
        "    plt.plot(epochs_range, loss, label=\"train loss\")\n",
        "    plt.plot(epochs_range, val_loss, label=\"validataion loss\")\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "\n",
        "    plt.subplot(3,2,2)\n",
        "    plt.plot(epochs_range, acc, label=\"train accuracy\")\n",
        "    plt.plot(epochs_range, val_acc, label=\"validataion accuracy\")\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc=\"upper right\")\n",
        "\n",
        "    plt.subplot(3,2,3)\n",
        "    plt.plot(epochs_range, f1, label=\"train f1_score\")\n",
        "    plt.plot(epochs_range, val_f1, label=\"validataion f1_score\")\n",
        "    plt.title(\"F1 Score\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"F1 Score\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "\n",
        "    plt.subplot(3,2,4)\n",
        "    plt.plot(epochs_range, iou, label=\"train Binary IoU\")\n",
        "    plt.plot(epochs_range, val_iou, label=\"validataion Binary IoU\")\n",
        "    plt.title(\"Binary IoU\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Binary IoU\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    plt.subplot(3,2,5)\n",
        "    plt.plot(epochs_range, precision, label=\"train precision\")\n",
        "    plt.plot(epochs_range, val_precision, label=\"validataion precision\")\n",
        "    plt.title(\"Precision\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.legend(loc=\"upper right\")\n",
        "\n",
        "    plt.subplot(3,2,6)\n",
        "    plt.plot(epochs_range, recall, label=\"train recall\")\n",
        "    plt.plot(epochs_range, val_recall, label=\"validataion recall\")\n",
        "    plt.title(\"Recall\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Recall\")\n",
        "    plt.legend(loc=\"upper right\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "display_learning_curves(model_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBbquNixeSvm"
      },
      "outputs": [],
      "source": [
        "def show_predictions(dataset, num):\n",
        "    for image, mask in dataset.take(num):\n",
        "        pred_mask = unet_model.predict(image)\n",
        "        pred_mask = tf.cast(pred_mask > 0.5, tf.uint8)\n",
        "        pred_mask = tf.cast(pred_mask * 255.0, tf.uint8)\n",
        "        display([image[0], mask[0], pred_mask[0]])\n",
        "\n",
        "show_predictions(test_batches, 1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
